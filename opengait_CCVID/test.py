# import torch
# print(torch.cuda.is_available())         # True
# print(torch.cuda.get_device_name(0))     # 'NVIDIA GeForce RTX 3070'



# import os
# import json

# json_path = "C:/Users/user/Desktop/capstone/Opengait-main/OpenGait-master/datasets/CCVID/CCVID.json"
# dataset_root = "C:/Users/user/Desktop/capstone/CCVID2_dataset"

# with open(json_path, "r") as f:
#     data = json.load(f)

# broken_samples = []
# total_samples = 0

# for pid in data["TRAIN_SET"]:
#     pid_path = os.path.join(dataset_root, pid)
#     if not os.path.isdir(pid_path):
#         print(f"âŒ {pid} ë””ë ‰í† ë¦¬ ì—†ìŒ")
#         continue

#     for root, _, files in os.walk(pid_path):
#         for file in files:
#             if file.endswith("0_heatmap.pkl"):
#                 total_samples += 1
#                 full_path = os.path.join(root, file)
#                 if os.path.islink(full_path):
#                     target = os.readlink(full_path)
#                     if not os.path.exists(target):
#                         broken_samples.append((pid, full_path, target))
#                         print(f"âš ï¸ ê¹¨ì§„ ë§í¬: {full_path} â†’ {target}")

# # ìš”ì•½ ì¶œë ¥
# print("\nğŸ“Š ìš”ì•½")
# print(f"ì „ì²´ heatmap ìƒ˜í”Œ ìˆ˜: {total_samples}")
# print(f"ê¹¨ì§„ heatmap ë§í¬ ìˆ˜: {len(broken_samples)}")

# if total_samples > 0:
#     ratio = len(broken_samples) / total_samples * 100
#     print(f"ê¹¨ì§„ ë¹„ìœ¨: {ratio:.2f}%")
# else:
#     print("âš ï¸ heatmap ìƒ˜í”Œì´ ì—†ìŠµë‹ˆë‹¤.")

# # (ì„ íƒ) ê¹¨ì§„ ìƒ˜í”Œ ëª©ë¡ IDë§Œ ë³´ê¸°
# broken_ids = sorted(set(pid for pid, _, _ in broken_samples))
# print(f"\nâš ï¸ ê¹¨ì§„ ID ìˆ˜: {len(broken_ids)}")
# print("ê¹¨ì§„ ID ëª©ë¡:", broken_ids)



# import os
# import pickle
# from collections import defaultdict

# base_path = "C:/Users/user/Desktop/capstone/CCVID2_dataset"
# len_counts = defaultdict(int)

# for root, dirs, files in os.walk(base_path):
#     for file in files:
#         if file.endswith(".pkl"):
#             file_path = os.path.join(root, file)
#             try:
#                 with open(file_path, "rb") as f:
#                     data = pickle.load(f)
#                 l = len(data)
#                 len_counts[l] += 1
#             except Exception as e:
#                 print(f"Error loading {file_path}: {e}")

# # ì •ë ¬í•´ì„œ ì¶œë ¥
# print("\nğŸ“Š len() ê°’ë³„ íŒŒì¼ ê°œìˆ˜:")
# for length in sorted(len_counts.keys()):
#     print(f"len = {length}: {len_counts[length]}ê°œ")


import os

root_dir = "C:/Users/user/Desktop/capstone/CCVID2_dataset"
missing_pose = []
missing_sil = []
complete = []
total = 0

for pid in os.listdir(root_dir):
    pid_path = os.path.join(root_dir, pid)
    if not os.path.isdir(pid_path):
        continue
    for seq_type in os.listdir(pid_path):
        type_path = os.path.join(pid_path, seq_type)
        for view in os.listdir(type_path):
            view_path = os.path.join(type_path, view)
            if not os.path.isdir(view_path):
                continue
            total += 1
            files = os.listdir(view_path)
            has_pose = any("pose" in f and f.endswith(".pkl") for f in files)
            has_sil = any("sil" in f and f.endswith(".pkl") for f in files)

            if has_pose and has_sil:
                complete.append(view_path)
            elif not has_pose:
                missing_pose.append(view_path)
                print(f"âš ï¸ Missing pose file: {view_path}")
            elif not has_sil:
                missing_sil.append(view_path)
                print(f"âš ï¸ Missing silhouette file: {view_path}")

print("\nğŸ” ê²€ì‚¬ ê²°ê³¼:")
print(f"ì´ ì‹œí€€ìŠ¤ í´ë” ìˆ˜: {total}")
print(f" - ì •ìƒ (pose + sil): {len(complete)}")
print(f" - pose ì—†ìŒ: {len(missing_pose)}")
print(f" - sil ì—†ìŒ: {len(missing_sil)}")

