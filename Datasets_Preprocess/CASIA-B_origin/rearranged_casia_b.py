import os
import cv2
import numpy as np
from ultralytics import YOLO
from collections import defaultdict
from tqdm import tqdm
import random
import shutil
import re

# ê²½ë¡œ ì„¤ì •
src_root = os.path.normpath('./CASIA-B-frame-reorganized')
dst_root = os.path.normpath('./CASIA-B-augmentation')

# YOLO ëª¨ë¸ ë¡œë“œ
seg_model = YOLO('yolov8m-seg.pt')
pose_model = YOLO('yolov8m-pose.pt')

# COCO 17 keypoints ì •ë³´
COCO_KEYPOINTS = [
    'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
    'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
    'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
    'left_knee', 'right_knee', 'left_ankle', 'right_ankle'
]

def is_image_file(filename):
    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))

def parse_casia_folder_name(folder_name):
    """CASIA-B í´ë”ëª… íŒŒì‹±: 001-bg-01 -> (person_id=001, condition=bg, sequence=01)"""
    parts = folder_name.split('-')
    if len(parts) == 3:
        person_id = parts[0]  # 001
        condition = parts[1]  # bg, cl, nm
        sequence = parts[2]   # 01, 03, 05
        return person_id, condition, sequence
    return None, None, None

def scan_casia_structure():
    """CASIA-B êµ¬ì¡° ìŠ¤ìº” - train/test í´ë” ëª¨ë‘ ì²˜ë¦¬"""
    print("\n=== CASIA-B êµ¬ì¡° ìŠ¤ìº” ===")
    
    all_data = []
    
    if not os.path.exists(src_root):
        print(f"Error: {src_root} ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        return []
    
    # trainê³¼ test í´ë” ëª¨ë‘ ìŠ¤ìº”
    for split_folder in ['train', 'test']:
        split_path = os.path.join(src_root, split_folder)
        
        if not os.path.exists(split_path):
            print(f"Warning: {split_path} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            continue
            
        print(f"ìŠ¤ìº” ì¤‘: {split_folder}")
        
        # ê° person-condition-sequence í´ë” ìŠ¤ìº”
        for folder_name in os.listdir(split_path):
            folder_path = os.path.join(split_path, folder_name)
            
            if not os.path.isdir(folder_path):
                continue
            
            # í´ë”ëª… íŒŒì‹±
            person_id, condition, sequence = parse_casia_folder_name(folder_name)
            if person_id is None:
                print(f"  ì•Œ ìˆ˜ ì—†ëŠ” í´ë” í˜•ì‹: {folder_name}")
                continue
            
            # ê° angle í´ë” ìŠ¤ìº” (000, 018, 036, ...)
            angle_folders = [d for d in os.listdir(folder_path) 
                           if os.path.isdir(os.path.join(folder_path, d))]
            
            if not angle_folders:
                print(f"  ê°ë„ í´ë” ì—†ìŒ: {folder_name}")
                continue
            
            for angle in sorted(angle_folders):
                angle_path = os.path.join(folder_path, angle)
                
                # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
                img_files = [f for f in os.listdir(angle_path) if is_image_file(f)]
                if not img_files:
                    continue
                
                print(f"  {folder_name}/{angle} -> ì´ë¯¸ì§€ {len(img_files)}ê°œ")
                
                # ê³ ìœ  ID ìƒì„±: person_condition_sequence_angle
                unique_id = f"{person_id}_{condition}_{sequence}_{angle}"
                path_info = f"{split_folder}/{folder_name}/{angle}"
                
                all_data.append({
                    'path_info': path_info,
                    'unique_id': unique_id,
                    'person_id': person_id,
                    'condition': condition,
                    'sequence': sequence,
                    'angle': angle,
                    'original_split': split_folder,
                    'img_count': len(img_files)
                })
    
    print(f"\nì „ì²´ ë°œê²¬ëœ ì‹œí€€ìŠ¤: {len(all_data)}ê°œ")
    return all_data

def reorganize_casia_data():
    """CASIA-B ë°ì´í„°ë¥¼ ìƒˆë¡œìš´ êµ¬ì¡°ë¡œ ì¬êµ¬ì„±"""
    all_data = scan_casia_structure()
    
    if not all_data:
        print("ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        return {}
    
    # ì‚¬ëŒë³„ë¡œ ê·¸ë£¹í™”
    person_groups = defaultdict(list)
    for data in all_data:
        person_groups[data['person_id']].append(data)
    
    print(f"\nì „ì²´ ì‚¬ëŒ ìˆ˜: {len(person_groups)}")
    
    # ê° ì‚¬ëŒë³„ ë°ì´í„° ë¶„í¬ ì¶œë ¥ (ì²˜ìŒ 10ëª…ë§Œ)
    print("\nì‚¬ëŒë³„ ë°ì´í„° ë¶„í¬ (ì²˜ìŒ 10ëª…):")
    for i, (person_id, sequences) in enumerate(sorted(person_groups.items())[:10]):
        conditions = defaultdict(int)
        angles = defaultdict(int)
        for seq in sequences:
            conditions[seq['condition']] += 1
            angles[seq['angle']] += 1
        print(f"  Person {person_id}: {len(sequences)}ê°œ ì‹œí€€ìŠ¤ - ì¡°ê±´{dict(conditions)} ê°ë„{dict(angles)}")
    
    if len(person_groups) > 10:
        print(f"  ... ì™¸ {len(person_groups)-10}ëª…")
    
    # ì‚¬ëŒ ID ë¦¬ìŠ¤íŠ¸ë¥¼ ì„ì–´ì„œ 6:2:2ë¡œ ë¶„í• 
    person_ids = list(person_groups.keys())
    random.shuffle(person_ids)
    
    total_persons = len(person_ids)
    train_size = int(total_persons * 0.6)
    gallery_size = int(total_persons * 0.2)
    
    train_persons = person_ids[:train_size]
    gallery_persons = person_ids[train_size:train_size + gallery_size]
    probe_persons = person_ids[train_size + gallery_size:]
    
    # ê° splitì— ë°ì´í„° í• ë‹¹
    data_dict = {
        'train': [],
        'gallery': [],
        'probe': []
    }
    
    for person_id in train_persons:
        data_dict['train'].extend(person_groups[person_id])
    
    for person_id in gallery_persons:
        data_dict['gallery'].extend(person_groups[person_id])
    
    for person_id in probe_persons:
        data_dict['probe'].extend(person_groups[person_id])
    
    print(f"\në°ì´í„° ë¶„í•  ê²°ê³¼:")
    print(f"  Train: {len(train_persons)}ëª… ({len(data_dict['train'])}ê°œ ì‹œí€€ìŠ¤)")
    print(f"  Gallery: {len(gallery_persons)}ëª… ({len(data_dict['gallery'])}ê°œ ì‹œí€€ìŠ¤)")
    print(f"  Probe: {len(probe_persons)}ëª… ({len(data_dict['probe'])}ê°œ ì‹œí€€ìŠ¤)")
    
    # ê° splitì˜ ì²˜ìŒ 5ê°œ ì‹œí€€ìŠ¤ ì¶œë ¥
    for split_name, split_data in data_dict.items():
        print(f"\n{split_name} ì‹œí€€ìŠ¤ (ì²˜ìŒ 5ê°œ):")
        for data in split_data[:5]:
            print(f"  - {data['unique_id']} ({data['path_info']}) - {data['img_count']}ì¥")
        if len(split_data) > 5:
            print(f"  ... ì™¸ {len(split_data)-5}ê°œ")
    
    return data_dict

def extract_silhouette_and_resize(img_path, target_size=64):
    """ì´ë¯¸ì§€ì—ì„œ ì‚¬ëŒ ì‹¤ë£¨ì—£ ì¶”ì¶œí•˜ê³  64x64ë¡œ ë¦¬ì‚¬ì´ì¦ˆ"""
    try:
        img = cv2.imread(img_path)
        if img is None:
            return None
        
        # YOLOv8 segmentation ì‹¤í–‰
        results = seg_model(img, verbose=False)
        
        # ê²°ê³¼ í™•ì¸
        if not results or not results[0].masks or len(results[0].masks) == 0:
            return None
        
        # ì‚¬ëŒ í´ë˜ìŠ¤(0)ì¸ ë§ˆìŠ¤í¬ë§Œ ì„ íƒ
        person_masks = []
        for i, cls in enumerate(results[0].boxes.cls):
            if int(cls) == 0:  # 0ì€ person í´ë˜ìŠ¤
                person_masks.append(results[0].masks.data[i].cpu().numpy())
        
        if len(person_masks) == 0:
            return None
        
        # ì—¬ëŸ¬ ì‚¬ëŒì´ ê²€ì¶œëœ ê²½ìš°, ê°€ì¥ í° ë§ˆìŠ¤í¬ ì„ íƒ
        if len(person_masks) > 1:
            areas = [mask.sum() for mask in person_masks]
            largest_idx = np.argmax(areas)
            final_mask = person_masks[largest_idx]
        else:
            final_mask = person_masks[0]
        
        # ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        h, w = img.shape[:2]
        final_mask = cv2.resize(final_mask, (w, h), interpolation=cv2.INTER_NEAREST)
        
        # ì´ì§„í™” (0 ë˜ëŠ” 255)
        silhouette = (final_mask > 0.5).astype(np.uint8) * 255
        
        # ì‹¤ë£¨ì—£ì—ì„œ ì‚¬ëŒ ì˜ì—­ ì°¾ê¸°
        coords = np.where(silhouette > 0)
        if len(coords[0]) == 0:
            return None
        
        y_min, y_max = coords[0].min(), coords[0].max()
        x_min, x_max = coords[1].min(), coords[1].max()
        
        # ë°”ìš´ë”© ë°•ìŠ¤ë¡œ í¬ë¡­
        cropped_silhouette = silhouette[y_min:y_max+1, x_min:x_max+1]
        cropped_h, cropped_w = cropped_silhouette.shape[:2]
        
        # ë¹„ìœ¨ ê³„ì‚°
        scale = min(target_size / cropped_w, target_size / cropped_h)
        
        # ìƒˆë¡œìš´ í¬ê¸° ê³„ì‚°
        new_w = int(cropped_w * scale)
        new_h = int(cropped_h * scale)
        
        # ë¦¬ì‚¬ì´ì¦ˆ
        resized = cv2.resize(cropped_silhouette, (new_w, new_h), interpolation=cv2.INTER_AREA)
        
        # íŒ¨ë”© ê³„ì‚°
        pad_w = target_size - new_w
        pad_h = target_size - new_h
        
        pad_left = pad_w // 2
        pad_right = pad_w - pad_left
        pad_top = pad_h // 2
        pad_bottom = pad_h - pad_top
        
        # íŒ¨ë”© ì ìš© (ê²€ì€ìƒ‰ ë°°ê²½)
        padded = cv2.copyMakeBorder(
            resized,
            pad_top, pad_bottom, pad_left, pad_right,
            cv2.BORDER_CONSTANT,
            value=0
        )
        
        return padded
        
    except Exception as e:
        print(f"ì‹¤ë£¨ì—£ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

def extract_pose_yolo(img_path):
    """YOLOv8 í¬ì¦ˆ ì¶”ì¶œ"""
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ í™•ì¸
        img = cv2.imread(img_path)
        if img is None:
            return None
        
        # ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
        h, w = img.shape[:2]
        if h <= 0 or w <= 0:
            return None
        
        # YOLOv8 pose ì‹¤í–‰
        results = pose_model(img, verbose=False)
        
        # ê²°ê³¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not results or len(results) == 0:
            return None
        
        result = results[0]
        if not hasattr(result, 'keypoints') or result.keypoints is None:
            return None
        
        if len(result.keypoints) == 0:
            return None
        
        if not hasattr(result.keypoints, 'xy') or result.keypoints.xy is None:
            return None
        
        if len(result.keypoints.xy) == 0:
            return None
        
        if not hasattr(result.keypoints, 'conf') or result.keypoints.conf is None:
            return None
        
        # ì²« ë²ˆì§¸ ì‚¬ëŒì˜ keypoints ê°€ì ¸ì˜¤ê¸°
        try:
            keypoints = result.keypoints.xy[0].cpu().numpy()  # (17, 2)
            confidences = result.keypoints.conf[0].cpu().numpy()  # (17,)
        except Exception:
            return None
        
        if keypoints.shape[0] != 17 or confidences.shape[0] != 17:
            return None
        
        # í¬ì¦ˆ ë°ì´í„° ìƒì„±
        pose_data = []
        for i in range(17):
            try:
                x, y = keypoints[i]
                conf = confidences[i]
                
                # NaN ê°’ í™•ì¸
                if np.isnan(x) or np.isnan(y) or np.isnan(conf):
                    x, y, conf = 0.0, 0.0, 0.0
                
                # ì •ê·œí™”ëœ ì¢Œí‘œë¡œ ë³€í™˜
                x_norm = float(x / w) if w > 0 else 0.0
                y_norm = float(y / h) if h > 0 else 0.0
                conf_val = float(conf)
                
                # ë²”ìœ„ í™•ì¸ (0~1)
                x_norm = max(0.0, min(1.0, x_norm))
                y_norm = max(0.0, min(1.0, y_norm))
                conf_val = max(0.0, min(1.0, conf_val))
                
                pose_data.append([x_norm, y_norm, 0.0, conf_val])
                
            except Exception:
                pose_data.append([0.0, 0.0, 0.0, 0.0])
        
        return pose_data
        
    except Exception:
        return None

def save_pose_to_txt(pose_data, txt_path):
    """COCO 17 keypointsë¥¼ txt íŒŒì¼ë¡œ ì €ì¥"""
    try:
        if pose_data is None or len(pose_data) != 17:
            return False
        
        os.makedirs(os.path.dirname(txt_path), exist_ok=True)
        
        with open(txt_path, 'w') as f:
            f.write("# COCO 17 keypoints format\n")
            f.write("# x_normalized y_normalized z confidence\n")
            for landmark in pose_data:
                if len(landmark) != 4:
                    continue
                f.write(f"{landmark[0]:.6f} {landmark[1]:.6f} {landmark[2]:.6f} {landmark[3]:.6f}\n")
        
        return True
        
    except Exception:
        return False

def generate_gei(silhouette_folder, output_path):
    """ì‹¤ë£¨ì—£ ì´ë¯¸ì§€ë“¤ë¡œë¶€í„° GEI ìƒì„±"""
    try:
        if not os.path.exists(silhouette_folder):
            return False
        
        # ì‹¤ë£¨ì—£ íŒŒì¼ ì°¾ê¸°
        all_files = os.listdir(silhouette_folder)
        silhouette_files = [f for f in all_files 
                           if f.endswith('.png') and not f.endswith('_gei.png') and not f.endswith('_origin.jpg')]
        
        if not silhouette_files:
            return False
        
        # ëª¨ë“  ì‹¤ë£¨ì—£ ì´ë¯¸ì§€ ë¡œë“œ
        silhouettes = []
        for file in sorted(silhouette_files):
            img_path = os.path.join(silhouette_folder, file)
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is not None:
                silhouettes.append(img.astype(np.float32))
        
        if not silhouettes:
            return False
        
        # GEI ê³„ì‚° (í‰ê· )
        gei = np.mean(silhouettes, axis=0).astype(np.uint8)
        
        # GEI ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        # GEI ì €ì¥
        success = cv2.imwrite(output_path, gei)
        return success
        
    except Exception:
        return False

def process_sequence(data_info, split_type, save_original=False):
    """ë‹¨ì¼ ì‹œí€€ìŠ¤ ì²˜ë¦¬"""
    try:
        src_folder = os.path.join(src_root, data_info['path_info'])
        
        # ëª©ì ì§€ í´ë” ì„¤ì •
        if split_type == 'train':
            person_folder = os.path.join(dst_root, 'train', data_info['person_id'])
            dst_folder = os.path.join(person_folder, 
                                    f"{data_info['condition']}-{data_info['sequence']}-{data_info['angle']}")
        elif split_type == 'gallery':
            person_folder = os.path.join(dst_root, 'test', 'gallery', data_info['person_id'])
            dst_folder = os.path.join(person_folder, 
                                    f"{data_info['condition']}-{data_info['sequence']}-{data_info['angle']}")
        else:  # probe
            person_folder = os.path.join(dst_root, 'test', 'probe', data_info['person_id'])
            dst_folder = os.path.join(person_folder, 
                                    f"{data_info['condition']}-{data_info['sequence']}-{data_info['angle']}")
        
        os.makedirs(dst_folder, exist_ok=True)
        os.makedirs(person_folder, exist_ok=True)  # person í´ë”ë„ ìƒì„±
        
        processed = 0
        failed = 0
        pose_success = 0
        pose_failed = 0
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì²˜ë¦¬
        img_files = [f for f in os.listdir(src_folder) if is_image_file(f)]
        
        for file in sorted(img_files):
            src_file = os.path.join(src_folder, file)
            base_name = os.path.splitext(file)[0]
            file_ext = os.path.splitext(file)[1]
            
            try:
                # ì›ë³¸ ì´ë¯¸ì§€ ë³µì‚¬ (ì˜µì…˜)
                if save_original:
                    origin_path = os.path.join(dst_folder, f"{base_name}_origin{file_ext}")
                    shutil.copy2(src_file, origin_path)
                
                # ì‹¤ë£¨ì—£ ì¶”ì¶œ ë° ë¦¬ì‚¬ì´ì¦ˆ
                silhouette = extract_silhouette_and_resize(src_file)
                if silhouette is None:
                    failed += 1
                    continue
                
                # ì‹¤ë£¨ì—£ ì €ì¥
                silhouette_path = os.path.join(dst_folder, f"{base_name}.png")
                cv2.imwrite(silhouette_path, silhouette)
                processed += 1
                
                # Pose ì¶”ì¶œ
                pose_data = extract_pose_yolo(src_file)
                if pose_data is not None:
                    pose_path = os.path.join(dst_folder, f"{base_name}_2d_pose.txt")
                    if save_pose_to_txt(pose_data, pose_path):
                        pose_success += 1
                    else:
                        pose_failed += 1
                else:
                    pose_failed += 1
                
            except Exception as e:
                print(f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ ({file}): {str(e)}")
                failed += 1
        
        # ğŸ”¥ GEI ìƒì„± - ìƒìœ„ í´ë”(person í´ë”)ì— ì €ì¥
        gei_generated = False
        if processed > 0:
            gei_filename = f"{data_info['condition']}-{data_info['sequence']}-{data_info['angle']}_gei.png"
            gei_path = os.path.join(person_folder, gei_filename)  # dst_folderê°€ ì•„ë‹Œ person_folderì— ì €ì¥
            gei_generated = generate_gei(dst_folder, gei_path)
        
        return processed, failed, pose_success, pose_failed, gei_generated
        
    except Exception as e:
        print(f"ì‹œí€€ìŠ¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return 0, 0, 0, 0, False


def process_data(data_dict, save_original=False):
    """ë°ì´í„° ì²˜ë¦¬"""
    total_processed = 0
    total_failed = 0
    total_pose_success = 0
    total_pose_failed = 0
    gei_generated = 0
    
    for split_type, data_list in data_dict.items():
        print(f"\nProcessing {split_type}...")
        
        with tqdm(total=len(data_list), desc=f"{split_type}") as pbar:
            for data_info in data_list:
                processed, failed, pose_success, pose_failed, gei_success = process_sequence(
                    data_info, split_type, save_original
                )
                
                total_processed += processed
                total_failed += failed
                total_pose_success += pose_success
                total_pose_failed += pose_failed
                if gei_success:
                    gei_generated += 1
                
                pbar.update(1)
    
    return total_processed, total_failed, total_pose_success, total_pose_failed, gei_generated

def print_statistics(data_dict):
    """í†µê³„ ì¶œë ¥"""
    print("\n=== CASIA-B ë°ì´í„° ë¶„í•  í†µê³„ ===")
    
    for split_type, data_list in data_dict.items():
        person_counts = defaultdict(int)
        condition_counts = defaultdict(int)
        angle_counts = defaultdict(int)
        
        for data in data_list:
            person_counts[data['person_id']] += 1
            condition_counts[data['condition']] += 1
            angle_counts[data['angle']] += 1
        
        print(f"\n{split_type}:")
        print(f"  - ì‹œí€€ìŠ¤ ìˆ˜: {len(data_list)}")
        print(f"  - ì‚¬ëŒ ìˆ˜: {len(person_counts)}")
        print(f"  - ì¡°ê±´ ë¶„í¬: {dict(condition_counts)}")
        print(f"  - ê°ë„ ë¶„í¬: {dict(angle_counts)}")
    
    # ì „ì²´ í†µê³„
    total_sequences = sum(len(data_list) for data_list in data_dict.values())
    total_persons = len(set(data['person_id'] for data_list in data_dict.values() for data in data_list))
    
    print(f"\nì „ì²´ í†µê³„:")
    print(f"  - ì „ì²´ ì‹œí€€ìŠ¤: {total_sequences}")
    print(f"  - ì „ì²´ ì‚¬ëŒ: {total_persons}")
    print(f"  - ë¶„í•  ë¹„ìœ¨: {len(data_dict['train'])} : {len(data_dict['gallery'])} : {len(data_dict['probe'])}")

def main(save_original=False):
    """ë©”ì¸ í•¨ìˆ˜"""
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸
    if os.path.exists(dst_root):
        response = input(f"\n{dst_root}ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() != 'y':
            print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
            return
        else:
            print(f"{dst_root} ì‚­ì œ ì¤‘...")
            shutil.rmtree(dst_root)
    
    # CASIA-B ë°ì´í„° êµ¬ì¡° ë¶„ì„ ë° ì¬êµ¬ì„±
    data_dict = reorganize_casia_data()
    
    if not data_dict or not any(data_dict.values()):
        print("ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")
        return
    
    # í†µê³„ ì¶œë ¥
    print_statistics(data_dict)
    
    # ì„¤ì • ì•ˆë‚´
    save_option_text = "ì›ë³¸ ì´ë¯¸ì§€ë„ í•¨ê»˜ ì €ì¥ë©ë‹ˆë‹¤." if save_original else "ì›ë³¸ ì´ë¯¸ì§€ëŠ” ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
    print(f"\nì„¤ì •: {save_option_text}")
    print("ğŸ”§ CASIA-B ë°ì´í„°ì…‹ êµ¬ì¡°ì— ë§ì¶° ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    print("ğŸ“ ì¶œë ¥ êµ¬ì¡°: person_id/condition-sequence-angle/")
    
    # ì‚¬ìš©ì í™•ì¸
    response = input("\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    if response.lower() != 'y':
        print("ì‘ì—…ì„ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ì²˜ë¦¬
    processed, failed, pose_success, pose_failed, gei_count = process_data(data_dict, save_original)
    
    print(f'\n=== ì²˜ë¦¬ ì™„ë£Œ ===')
    print(f'ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed}')
    print(f'ì²˜ë¦¬ ì‹¤íŒ¨í•œ ì´ë¯¸ì§€: {failed}')
    print(f'í¬ì¦ˆ ì¶”ì¶œ ì„±ê³µ: {pose_success}')
    print(f'í¬ì¦ˆ ì¶”ì¶œ ì‹¤íŒ¨: {pose_failed}')
    print(f'ìƒì„±ëœ GEI ì´ë¯¸ì§€: {gei_count}')
    if processed + failed > 0:
        print(f'ì‹¤ë£¨ì—£ ì¶”ì¶œ ì„±ê³µë¥ : {processed/(processed+failed)*100:.1f}%')
    if pose_success + pose_failed > 0:
        print(f'í¬ì¦ˆ ì¶”ì¶œ ì„±ê³µë¥ : {pose_success/(pose_success+pose_failed)*100:.1f}%')

if __name__ == '__main__':
    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€ ì„¤ì •
    SAVE_ORIGINAL = False
    
    main(save_original=SAVE_ORIGINAL)
